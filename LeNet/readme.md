# LeNet

## 1.网络结构

![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/06327858559efb1e284a626dd261b1ac.png)

LeNet 一开始是为了处理手写数字的识别而出现了，所以它的网络结构较浅，但是它也奠定了之后深度图像识别网络的基础。

由于 LeNet 是较早期的网络，所以下面详细介绍每一层网络的结构：

- **输入**：32x32的灰度图像，也就是一个通道，那么一个图像就是一个2维的矩阵，没有RGB三个通道。
- **Layer1**：6个大小为5x5的卷积核，步长为1。因此，到这里的输出变成了28x28x6。
- **Layer2**：2x2大小的池化层，使用的是average pooling，步长为2。那么这一层的输出就是14x14x6。
- **Layer3**：16个大小为5x5的卷积核，步长为1。但是，这一层16个卷积核中只有10个和前面的6层相连接。也就是说，这16个卷积核并不是扫描前一层所有的6个通道。如下图，0 1 2 3 4 5这 6个卷积核是扫描3个相邻，然后是6 7 8这3个卷积核是扫描4个相邻，9 10 11 12 13 14这6个是扫描4个非相邻，最后一个15扫描6个。实际上前面的6通道每个都只有10个卷积核扫描到。
- **Layer4**：和第二层一样，2x2大小的池化层，使用的是average pooling，步长为2。
- **Layer5**：全连接卷积层，120个卷积核，大小为1x1。
  第四层结束输出为16x5x5，相当于这里16x5x5展开为400个特征，然后使用120神经元去做全连接
- **Layer6**：全连接层，隐藏单元是84个。
- **Layer7**：输出层，输出单元是10个，因为数字识别是0-9。

## 2.总结

1. 卷积网络使用一个3层的序列组合：卷积、下采样 (池化)、非线性映射 ,这奠定了之后深层图像识别网络的基础
2. 使用卷积提取空间特征
3. 使用映射的空间均值进行下采样
4. 使用Sigmod函数进行非线性映射
5. 多层神经网络 (MLP) 作为最终的分类器
6. 层间的稀疏连接矩阵以避免巨大的计算开销